{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medición del Rendimiento de un Modelo de Clasificación con Regresión Logística\n",
    "\n",
    "# Importar bibliotecas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos de cáncer de mama\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data \n",
    "y = data.target # (0: No cáncer, 1: Cáncer)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión del modelo\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Precisión: {accuracy:.2f}')\n",
    "\n",
    "# Predicciones sobre el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión:\\n', conf_matrix)\n",
    "\n",
    "# Visualización de la matriz de confusión\n",
    "plt.matshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Valor verdadero')\n",
    "plt.xlabel('Valor predicho')\n",
    "plt.show()\n",
    "\n",
    "# Validación cruzada para una evaluación más robusta del modelo\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(f'Precisión media de validación cruzada: {cv_scores.mean():.2f}')\n",
    "\n",
    "# Generar la curva ROC\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Área bajo la curva (AUC): {roc_auc:.2f}')\n",
    "\n",
    "# Visualización de la curva ROC\n",
    "plt.plot(fpr, tpr, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Línea de referencia\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
